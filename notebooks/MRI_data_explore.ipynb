{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duke Breast Cancer MRI Dataset Explorer\n",
    "\n",
    "This notebook helps explore and analyze the Duke Breast Cancer MRI dataset with the following structure:\n",
    "```\n",
    "root_dir/\n",
    "├── Breast_MRI_001/\n",
    "│   └── patient_directory/\n",
    "│       ├── dynamic_sequence_1/\n",
    "│       │   └── *.dcm files\n",
    "│       ├── dynamic_sequence_2/\n",
    "│       │   └── *.dcm files\n",
    "│       └── ...\n",
    "├── Breast_MRI_002/\n",
    "└── ...\n",
    "```\n",
    "\n",
    "We'll use Python libraries for DICOM file processing and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "!pip install pydicom matplotlib numpy pandas seaborn tqdm pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "from collections import defaultdict, Counter\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset Detection Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_dataset_structure(root_dir):\n",
    "    \"\"\"\n",
    "    Explore the dataset structure and return summary statistics.\n",
    "    \"\"\"\n",
    "    print(f\"Analyzing dataset structure in: {root_dir}\")\n",
    "    \n",
    "    # Dictionary to store structure information\n",
    "    dataset_info = {\n",
    "        'total_patients': 0,\n",
    "        'total_studies': 0,\n",
    "        'total_sequences': 0,\n",
    "        'total_dcm_files': 0,\n",
    "        'patient_ids': [],\n",
    "        'patient_details': {}\n",
    "    }\n",
    "    \n",
    "    # Check if root directory exists\n",
    "    if not os.path.exists(root_dir):\n",
    "        print(f\"Error: The directory {root_dir} does not exist.\")\n",
    "        return dataset_info\n",
    "    \n",
    "    # Loop through first level directories (Breast_MRI_XXX)\n",
    "    for patient_folder in sorted(os.listdir(root_dir)):\n",
    "        patient_path = os.path.join(root_dir, patient_folder)\n",
    "        \n",
    "        if not os.path.isdir(patient_path) or not patient_folder.startswith('Breast_MRI_'):\n",
    "            continue\n",
    "            \n",
    "        dataset_info['total_patients'] += 1\n",
    "        dataset_info['patient_ids'].append(patient_folder)\n",
    "        \n",
    "        patient_info = {\n",
    "            'patient_directory': None,\n",
    "            'sequences': [],\n",
    "            'sequence_counts': {},\n",
    "            'total_files': 0\n",
    "        }\n",
    "        \n",
    "        # Find patient_directory within Breast_MRI_XXX\n",
    "        patient_subdirs = [d for d in os.listdir(patient_path) if os.path.isdir(os.path.join(patient_path, d))]\n",
    "        \n",
    "        if len(patient_subdirs) > 0:\n",
    "            patient_directory = patient_subdirs[0]  # Assuming there's only one directory per patient\n",
    "            patient_info['patient_directory'] = patient_directory\n",
    "            dataset_info['total_studies'] += 1\n",
    "            \n",
    "            patient_dir_path = os.path.join(patient_path, patient_directory)\n",
    "            \n",
    "            # Loop through sequences\n",
    "            for sequence_folder in sorted(os.listdir(patient_dir_path)):\n",
    "                sequence_path = os.path.join(patient_dir_path, sequence_folder)\n",
    "                \n",
    "                if os.path.isdir(sequence_path):\n",
    "                    dataset_info['total_sequences'] += 1\n",
    "                    patient_info['sequences'].append(sequence_folder)\n",
    "                    \n",
    "                    # Count DICOM files\n",
    "                    dcm_files = [f for f in os.listdir(sequence_path) if f.endswith('.dcm')]\n",
    "                    file_count = len(dcm_files)\n",
    "                    patient_info['sequence_counts'][sequence_folder] = file_count\n",
    "                    patient_info['total_files'] += file_count\n",
    "                    dataset_info['total_dcm_files'] += file_count\n",
    "        \n",
    "        dataset_info['patient_details'][patient_folder] = patient_info\n",
    "    \n",
    "    return dataset_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_dataset_summary(dataset_info):\n",
    "    \"\"\"\n",
    "    Display summary statistics of the dataset.\n",
    "    \"\"\"\n",
    "    print(\"\\n===== DATASET SUMMARY =====\")\n",
    "    print(f\"Total patients (Breast_MRI_XXX folders): {dataset_info['total_patients']}\")\n",
    "    print(f\"Total studies (patient directories): {dataset_info['total_studies']}\")\n",
    "    print(f\"Total sequences: {dataset_info['total_sequences']}\")\n",
    "    print(f\"Total DICOM files: {dataset_info['total_dcm_files']}\")\n",
    "    \n",
    "    if dataset_info['total_patients'] > 0:\n",
    "        avg_sequences = dataset_info['total_sequences'] / dataset_info['total_patients']\n",
    "        avg_files = dataset_info['total_dcm_files'] / dataset_info['total_patients']\n",
    "        print(f\"Average sequences per patient: {avg_sequences:.2f}\")\n",
    "        print(f\"Average DICOM files per patient: {avg_files:.2f}\")\n",
    "        \n",
    "        # Collect sequence names across patients\n",
    "        all_sequences = []\n",
    "        for patient_id, details in dataset_info['patient_details'].items():\n",
    "            all_sequences.extend(details['sequences'])\n",
    "            \n",
    "        sequence_counts = Counter(all_sequences)\n",
    "        print(\"\\nMost common sequence names:\")\n",
    "        for seq, count in sequence_counts.most_common(10):\n",
    "            print(f\"  - {seq}: {count} occurrences\")\n",
    "            \n",
    "        # Sample of patients\n",
    "        print(\"\\nSample of patient IDs:\")\n",
    "        for patient_id in sorted(dataset_info['patient_ids'])[:5]:\n",
    "            print(f\"  - {patient_id}\")\n",
    "        if len(dataset_info['patient_ids']) > 5:\n",
    "            print(f\"  - ... and {len(dataset_info['patient_ids']) - 5} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Detect the Duke Breast Cancer MRI Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the root directory path\n",
    "root_dir = \"../data/Duke-Breast-Cancer-MRI\"  # Change this to your actual path\n",
    "\n",
    "# Detect dataset structure\n",
    "dataset_info = detect_dataset_structure(root_dir)\n",
    "\n",
    "# Display summary\n",
    "display_dataset_summary(dataset_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyze DICOM Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_dicom_metadata(dataset_info, root_dir, sample_size=5):\n",
    "    \"\"\"\n",
    "    Sample DICOM files from different patients and extract metadata.\n",
    "    \"\"\"\n",
    "    metadata_samples = []\n",
    "    sample_count = 0\n",
    "    \n",
    "    # Try to get samples from different patients\n",
    "    for patient_id in dataset_info['patient_ids']:\n",
    "        if sample_count >= sample_size:\n",
    "            break\n",
    "            \n",
    "        patient_details = dataset_info['patient_details'][patient_id]\n",
    "        patient_dir = os.path.join(root_dir, patient_id, patient_details['patient_directory'])\n",
    "        \n",
    "        # Try each sequence\n",
    "        for sequence in patient_details['sequences']:\n",
    "            if sample_count >= sample_size:\n",
    "                break\n",
    "                \n",
    "            sequence_path = os.path.join(patient_dir, sequence)\n",
    "            dcm_files = [f for f in os.listdir(sequence_path) if f.endswith('.dcm')]\n",
    "            \n",
    "            if dcm_files:\n",
    "                # Get the first DICOM file\n",
    "                dicom_path = os.path.join(sequence_path, dcm_files[0])\n",
    "                try:\n",
    "                    dcm = pydicom.dcmread(dicom_path)\n",
    "                    metadata_samples.append({\n",
    "                        'patient_id': patient_id,\n",
    "                        'sequence': sequence,\n",
    "                        'file': dcm_files[0],\n",
    "                        'dicom': dcm\n",
    "                    })\n",
    "                    sample_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading DICOM file {dicom_path}: {e}\")\n",
    "    \n",
    "    return metadata_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_dicom_metadata(metadata_samples):\n",
    "    \"\"\"\n",
    "    Display metadata from sampled DICOM files.\n",
    "    \"\"\"\n",
    "    common_tags = ['PatientName', 'PatientID', 'PatientBirthDate', 'PatientSex',\n",
    "                   'StudyDescription', 'SeriesDescription', 'Modality',\n",
    "                   'Manufacturer', 'ManufacturerModelName', 'MagneticFieldStrength',\n",
    "                   'PixelSpacing', 'SliceThickness', 'RepetitionTime', 'EchoTime']\n",
    "    \n",
    "    for i, sample in enumerate(metadata_samples, 1):\n",
    "        dcm = sample['dicom']\n",
    "        print(f\"\\n===== DICOM Sample {i} =====\")\n",
    "        print(f\"Patient ID: {sample['patient_id']}\")\n",
    "        print(f\"Sequence: {sample['sequence']}\")\n",
    "        print(f\"File: {sample['file']}\")\n",
    "        print(\"\\nKey Metadata:\")\n",
    "        \n",
    "        for tag in common_tags:\n",
    "            if hasattr(dcm, tag):\n",
    "                print(f\"  - {tag}: {getattr(dcm, tag)}\")\n",
    "        \n",
    "        print(f\"\\nImage dimensions: {dcm.Rows} x {dcm.Columns}\")\n",
    "        if hasattr(dcm, 'NumberOfFrames'):\n",
    "            print(f\"Number of frames: {dcm.NumberOfFrames}\")\n",
    "        \n",
    "        # Add more MRI-specific tags\n",
    "        mri_tags = ['ScanningSequence', 'SequenceVariant', 'ScanOptions', 'ContrastBolusAgent']\n",
    "        print(\"\\nMRI-specific tags:\")\n",
    "        for tag in mri_tags:\n",
    "            if hasattr(dcm, tag):\n",
    "                print(f\"  - {tag}: {getattr(dcm, tag)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample DICOM metadata\n",
    "metadata_samples = sample_dicom_metadata(dataset_info, root_dir, sample_size=3)\n",
    "\n",
    "# Display metadata\n",
    "if metadata_samples:\n",
    "    display_dicom_metadata(metadata_samples)\n",
    "else:\n",
    "    print(\"No DICOM samples could be extracted. Please check the dataset structure.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize MRI Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_dicom_samples(metadata_samples, rows=1):\n",
    "    \"\"\"\n",
    "    Visualize sample DICOM images.\n",
    "    \"\"\"\n",
    "    if not metadata_samples:\n",
    "        print(\"No samples to visualize.\")\n",
    "        return\n",
    "    \n",
    "    n_samples = min(rows * 2, len(metadata_samples))\n",
    "    fig, axes = plt.subplots(rows, 2, figsize=(15, 5 * rows))\n",
    "    if rows == 1:\n",
    "        axes = [axes]  # Make axes indexable for the single row case\n",
    "    \n",
    "    for i, sample in enumerate(metadata_samples[:n_samples]):\n",
    "        row, col = i // 2, i % 2\n",
    "        ax = axes[row][col]\n",
    "        \n",
    "        dcm = sample['dicom']\n",
    "        \n",
    "        # Get the pixel array\n",
    "        try:\n",
    "            pixel_array = dcm.pixel_array\n",
    "            \n",
    "            # For multi-frame DICOM, display the middle frame\n",
    "            if len(pixel_array.shape) > 2 and pixel_array.shape[0] > 1:\n",
    "                middle_frame = pixel_array.shape[0] // 2\n",
    "                image_data = pixel_array[middle_frame]\n",
    "                frame_info = f\" (frame {middle_frame+1}/{pixel_array.shape[0]})\"\n",
    "            else:\n",
    "                image_data = pixel_array\n",
    "                frame_info = \"\"\n",
    "            \n",
    "            # Normalize image for display\n",
    "            if image_data.max() > 0:\n",
    "                image_data = (image_data / image_data.max()) * 255\n",
    "            \n",
    "            # Display the image\n",
    "            ax.imshow(image_data, cmap='gray')\n",
    "            ax.set_title(f\"{sample['patient_id']}\\n{sample['sequence']}{frame_info}\")\n",
    "            ax.axis('off')\n",
    "            \n",
    "        except Exception as e:\n",
    "            ax.text(0.5, 0.5, f\"Error: {str(e)}\", ha='center', va='center')\n",
    "            ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample DICOM images\n",
    "if metadata_samples:\n",
    "    visualize_dicom_samples(metadata_samples, rows=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyze Sequences and Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dynamic_sequence(patient_id, sequence_name, root_dir, dataset_info):\n",
    "    \"\"\"\n",
    "    Analyze a dynamic sequence of DICOM files.\n",
    "    \"\"\"\n",
    "    patient_details = dataset_info['patient_details'].get(patient_id)\n",
    "    if not patient_details or sequence_name not in patient_details['sequences']:\n",
    "        print(f\"Sequence {sequence_name} not found for patient {patient_id}\")\n",
    "        return None\n",
    "    \n",
    "    sequence_path = os.path.join(root_dir, patient_id, patient_details['patient_directory'], sequence_name)\n",
    "    dcm_files = sorted([f for f in os.listdir(sequence_path) if f.endswith('.dcm')])\n",
    "    \n",
    "    if not dcm_files:\n",
    "        print(f\"No DICOM files found in {sequence_path}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"\\nAnalyzing sequence {sequence_name} for patient {patient_id}\")\n",
    "    print(f\"Total DICOM files: {len(dcm_files)}\")\n",
    "    \n",
    "    # Load a sample of DICOM files to analyze the sequence\n",
    "    sample_size = min(10, len(dcm_files))\n",
    "    sample_indices = np.linspace(0, len(dcm_files)-1, sample_size, dtype=int)\n",
    "    \n",
    "    sequence_data = []\n",
    "    for idx in sample_indices:\n",
    "        file_path = os.path.join(sequence_path, dcm_files[idx])\n",
    "        try:\n",
    "            dcm = pydicom.dcmread(file_path)\n",
    "            \n",
    "            # Extract acquisition time if available\n",
    "            acquisition_time = getattr(dcm, 'AcquisitionTime', f\"Unknown-{idx}\")\n",
    "            \n",
    "            # Check for multi-frame DICOM\n",
    "            if hasattr(dcm, 'NumberOfFrames') and int(dcm.NumberOfFrames) > 1:\n",
    "                frames = dcm.pixel_array.shape[0]\n",
    "                # Get middle frame for analysis\n",
    "                middle_frame = frames // 2\n",
    "                image_data = dcm.pixel_array[middle_frame]\n",
    "                frame_info = f\"Multi-frame ({frames} frames)\"\n",
    "            else:\n",
    "                image_data = dcm.pixel_array\n",
    "                frame_info = \"Single frame\"\n",
    "            \n",
    "            # Calculate basic image statistics\n",
    "            sequence_data.append({\n",
    "                'file': dcm_files[idx],\n",
    "                'acquisition_time': acquisition_time,\n",
    "                'frame_info': frame_info,\n",
    "                'shape': image_data.shape,\n",
    "                'min': float(np.min(image_data)),\n",
    "                'max': float(np.max(image_data)),\n",
    "                'mean': float(np.mean(image_data)),\n",
    "                'std': float(np.std(image_data))\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "    \n",
    "    return sequence_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sequence_statistics(sequence_data):\n",
    "    \"\"\"\n",
    "    Visualize statistics of a sequence's DICOM files.\n",
    "    \"\"\"\n",
    "    if not sequence_data:\n",
    "        print(\"No sequence data to visualize.\")\n",
    "        return\n",
    "    \n",
    "    # Convert to DataFrame for easier visualization\n",
    "    df = pd.DataFrame(sequence_data)\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Plot mean intensity across files\n",
    "    axes[0, 0].plot(df.index, df['mean'], 'o-', color='blue')\n",
    "    axes[0, 0].set_title('Mean Intensity Across Sequence')\n",
    "    axes[0, 0].set_xlabel('File Index')\n",
    "    axes[0, 0].set_ylabel('Mean Intensity')\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    # Plot min/max intensity range\n",
    "    axes[0, 1].plot(df.index, df['min'], 'o-', color='blue', label='Min')\n",
    "    axes[0, 1].plot(df.index, df['max'], 'o-', color='red', label='Max')\n",
    "    axes[0, 1].fill_between(df.index, df['min'], df['max'], alpha=0.2)\n",
    "    axes[0, 1].set_title('Min/Max Intensity Range')\n",
    "    axes[0, 1].set_xlabel('File Index')\n",
    "    axes[0, 1].set_ylabel('Intensity')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    # Plot standard deviation\n",
    "    axes[1, 0].plot(df.index, df['std'], 'o-', color='green')\n",
    "    axes[1, 0].set_title('Standard Deviation Across Sequence')\n",
    "    axes[1, 0].set_xlabel('File Index')\n",
    "    axes[1, 0].set_ylabel('Standard Deviation')\n",
    "    axes[1, 0].grid(True)\n",
    "    \n",
    "    # Display file information\n",
    "    file_info = '\\n'.join([f\"{i}: {row['file']} ({row['frame_info']})\" \n",
    "                          for i, row in df.iterrows()])\n",
    "    axes[1, 1].text(0.1, 0.5, file_info, fontsize=9, va='center')\n",
    "    axes[1, 1].set_title('File Information')\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a patient and sequence to analyze\n",
    "# Replace with actual patient ID and sequence name from your dataset\n",
    "if dataset_info['patient_ids']:\n",
    "    sample_patient_id = dataset_info['patient_ids'][0]\n",
    "    \n",
    "    patient_details = dataset_info['patient_details'][sample_patient_id]\n",
    "    if patient_details['sequences']:\n",
    "        sample_sequence = patient_details['sequences'][0]\n",
    "        \n",
    "        # Analyze the dynamic sequence\n",
    "        sequence_data = analyze_dynamic_sequence(sample_patient_id, sample_sequence, root_dir, dataset_info)\n",
    "        \n",
    "        # Visualize sequence statistics\n",
    "        if sequence_data:\n",
    "            visualize_sequence_statistics(sequence_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Extract and Analyze ROI Data (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_segmentations(dataset_info, root_dir):\n",
    "    \"\"\"\n",
    "    Search for segmentation data or ROI information in the dataset.\n",
    "    \"\"\"\n",
    "    print(\"\\nSearching for segmentation data or ROI information...\")\n",
    "    \n",
    "    segmentation_info = {\n",
    "        'found': False,\n",
    "        'locations': [],\n",
    "        'types': set()\n",
    "    }\n",
    "    \n",
    "    # Common segmentation-related terms to look for in folder/file names\n",
    "    roi_terms = ['roi', 'segmentation', 'mask', 'contour', 'tumor', 'lesion']\n",
    "    \n",
    "    # Check each patient folder for segmentation data\n",
    "    for patient_id in dataset_info['patient_ids']:\n",
    "        patient_details = dataset_info['patient_details'][patient_id]\n",
    "        patient_dir = os.path.join(root_dir, patient_id, patient_details['patient_directory'])\n",
    "        \n",
    "        # Check sequence names for ROI-related terms\n",
    "        for sequence in patient_details['sequences']:\n",
    "            if any(term in sequence.lower() for term in roi_terms):\n",
    "                segmentation_info['found'] = True\n",
    "                segmentation_info['locations'].append({\n",
    "                    'patient_id': patient_id,\n",
    "                    'sequence': sequence,\n",
    "                    'path': os.path.join(patient_dir, sequence)\n",
    "                })\n",
    "                segmentation_info['types'].add(sequence)\n",
    "    \n",
    "    # Report findings\n",
    "    if segmentation_info['found']:\n",
    "        print(f\"Found potential segmentation/ROI data in {len(segmentation_info['locations'])} locations.\")\n",
    "        print(f\"Types of potential segmentation data: {', '.join(segmentation_info['types'])}\")\n",
    "    else:\n",
    "        print(\"No obvious segmentation/ROI data found based on folder naming.\")\n",
    "        print(\"You may need to check the DICOM metadata for ROI\")\n",
    "        print(\"No obvious segmentation/ROI data found based on folder naming.\")\n",
    "        print(\"You may need to check the DICOM metadata for ROI information.\")\n",
    "    \n",
    "    return segmentation_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for segmentation data\n",
    "segmentation_info = search_for_segmentations(dataset_info, root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Analyze DCE-MRI Enhancement Curves (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_dce_sequences(dataset_info):\n",
    "    \"\"\"\n",
    "    Identify potential DCE-MRI sequences in the dataset.\n",
    "    \"\"\"\n",
    "    print(\"\\nChecking for potential DCE-MRI sequences...\")\n",
    "    \n",
    "    dce_terms = ['dce', 'dynamic', 'contrast', 'enhanced', 'pre', 'post']\n",
    "    potential_dce_sequences = []\n",
    "    \n",
    "    for patient_id in dataset_info['patient_ids']:\n",
    "        patient_details = dataset_info['patient_details'][patient_id]\n",
    "        \n",
    "        # Group sequences that might be part of the same DCE-MRI series\n",
    "        dce_sequences = []\n",
    "        for sequence in patient_details['sequences']:\n",
    "            if any(term in sequence.lower() for term in dce_terms):\n",
    "                dce_sequences.append({\n",
    "                    'patient_id': patient_id,\n",
    "                    'sequence': sequence,\n",
    "                    'file_count': patient_details['sequence_counts'].get(sequence, 0)\n",
    "                })\n",
    "        \n",
    "        if dce_sequences:\n",
    "            potential_dce_sequences.append({\n",
    "                'patient_id': patient_id,\n",
    "                'sequences': dce_sequences,\n",
    "                'total_sequences': len(dce_sequences)\n",
    "            })\n",
    "    \n",
    "    # Report findings\n",
    "    if potential_dce_sequences:\n",
    "        print(f\"Found potential DCE-MRI data for {len(potential_dce_sequences)} patients.\")\n",
    "        \n",
    "        # Display sample\n",
    "        sample_idx = min(3, len(potential_dce_sequences))\n",
    "        for i in range(sample_idx):\n",
    "            patient_data = potential_dce_sequences[i]\n",
    "            print(f\"\\nPatient {patient_data['patient_id']} has {patient_data['total_sequences']} potential DCE sequences:\")\n",
    "            for seq in patient_data['sequences']:\n",
    "                print(f\"  - {seq['sequence']} ({seq['file_count']} files)\")\n",
    "    else:\n",
    "        print(\"No obvious DCE-MRI sequences found based on folder naming.\")\n",
    "    \n",
    "    return potential_dce_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for DCE-MRI sequences\n",
    "dce_sequences = check_for_dce_sequences(dataset_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Extract Patient Demographics and Clinical Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_demographics(dataset_info, root_dir, sample_size=10):\n",
    "    \"\"\"\n",
    "    Extract patient demographics from DICOM metadata.\n",
    "    \"\"\"\n",
    "    print(\"\\nExtracting patient demographics from DICOM metadata...\")\n",
    "    \n",
    "    demographics = []\n",
    "    \n",
    "    # Sample patients\n",
    "    sample_patients = dataset_info['patient_ids'][:sample_size]\n",
    "    \n",
    "    for patient_id in sample_patients:\n",
    "        patient_details = dataset_info['patient_details'][patient_id]\n",
    "        patient_dir = os.path.join(root_dir, patient_id, patient_details['patient_directory'])\n",
    "        \n",
    "        # Try to find a DICOM file to extract demographics\n",
    "        for sequence in patient_details['sequences']:\n",
    "            sequence_path = os.path.join(patient_dir, sequence)\n",
    "            dcm_files = [f for f in os.listdir(sequence_path) if f.endswith('.dcm')]\n",
    "            \n",
    "            if dcm_files:\n",
    "                # Get the first DICOM file\n",
    "                dicom_path = os.path.join(sequence_path, dcm_files[0])\n",
    "                try:\n",
    "                    dcm = pydicom.dcmread(dicom_path)\n",
    "                    \n",
    "                    # Extract demographic information\n",
    "                    patient_info = {\n",
    "                        'patient_id': patient_id,\n",
    "                        'patient_name': str(getattr(dcm, 'PatientName', 'Unknown')),\n",
    "                        'patient_id_dicom': str(getattr(dcm, 'PatientID', 'Unknown')),\n",
    "                        'patient_sex': str(getattr(dcm, 'PatientSex', 'Unknown')),\n",
    "                        'patient_age': str(getattr(dcm, 'PatientAge', 'Unknown')),\n",
    "                        'study_date': str(getattr(dcm, 'StudyDate', 'Unknown')),\n",
    "                        'study_description': str(getattr(dcm, 'StudyDescription', 'Unknown'))\n",
    "                    }\n",
    "                    \n",
    "                    demographics.append(patient_info)\n",
    "                    break  # Found a DICOM file for this patient\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading DICOM file {dicom_path}: {e}\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    if demographics:\n",
    "        demographics_df = pd.DataFrame(demographics)\n",
    "        return demographics_df\n",
    "    else:\n",
    "        print(\"No demographic information could be extracted.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract demographics\n",
    "demographics_df = extract_demographics(dataset_info, root_dir)\n",
    "\n",
    "# Display demographics if available\n",
    "if demographics_df is not None:\n",
    "    display(demographics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Data Export Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_dicom_to_nifti(patient_id, sequence_name, root_dir, dataset_info, output_dir=\"nifti_exports\"):\n",
    "    \"\"\"\n",
    "    Export DICOM series to NIfTI format.\n",
    "    Note: This requires additional libraries like dicom2nifti or nibabel.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import dicom2nifti\n",
    "    except ImportError:\n",
    "        print(\"Please install dicom2nifti package: pip install dicom2nifti\")\n",
    "        return\n",
    "    \n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    patient_details = dataset_info['patient_details'].get(patient_id)\n",
    "    if not patient_details or sequence_name not in patient_details['sequences']:\n",
    "        print(f\"Sequence {sequence_name} not found for patient {patient_id}\")\n",
    "        return None\n",
    "    \n",
    "    # Construct paths\n",
    "    sequence_path = os.path.join(root_dir, patient_id, patient_details['patient_directory'], sequence_name)\n",
    "    output_file = os.path.join(output_dir, f\"{patient_id}_{sequence_name}.nii.gz\")\n",
    "    \n",
    "    try:\n",
    "        # Convert DICOM to NIfTI\n",
    "        dicom2nifti.convert_directory(sequence_path, output_file)\n",
    "        print(f\"Successfully exported to {output_file}\")\n",
    "        return output_file\n",
    "    except Exception as e:\n",
    "        print(f\"Error exporting to NIfTI: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_dataset_info_to_csv(dataset_info, output_file=\"dataset_info.csv\"):\n",
    "    \"\"\"\n",
    "    Export dataset information to CSV.\n",
    "    \"\"\"\n",
    "    # Prepare data for CSV\n",
    "    data = []\n",
    "    \n",
    "    for patient_id in dataset_info['patient_ids']:\n",
    "        patient_details = dataset_info['patient_details'][patient_id]\n",
    "        \n",
    "        for sequence in patient_details['sequences']:\n",
    "            data.append({\n",
    "                'patient_id': patient_id,\n",
    "                'patient_directory': patient_details['patient_directory'],\n",
    "                'sequence': sequence,\n",
    "                'file_count': patient_details['sequence_counts'].get(sequence, 0)\n",
    "            })\n",
    "    \n",
    "    # Create DataFrame and export\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Dataset information exported to {output_file}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dataset information to CSV\n",
    "dataset_df = export_dataset_info_to_csv(dataset_info)\n",
    "\n",
    "# Display summary of exported data\n",
    "display(dataset_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Create 3D Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_3d_mri_visualization(patient_id, sequence_name, root_dir, dataset_info):\n",
    "    \"\"\"\n",
    "    Create a 3D visualization of an MRI sequence using slices.\n",
    "    \"\"\"\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    \n",
    "    patient_details = dataset_info['patient_details'].get(patient_id)\n",
    "    if not patient_details or sequence_name not in patient_details['sequences']:\n",
    "        print(f\"Sequence {sequence_name} not found for patient {patient_id}\")\n",
    "        return None\n",
    "    \n",
    "    sequence_path = os.path.join(root_dir, patient_id, patient_details['patient_directory'], sequence_name)\n",
    "    dcm_files = sorted([f for f in os.listdir(sequence_path) if f.endswith('.dcm')])\n",
    "    \n",
    "    if not dcm_files:\n",
    "        print(f\"No DICOM files found in {sequence_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Load up to 10 slices for visualization\n",
    "    max_slices = min(10, len(dcm_files))\n",
    "    slices = []\n",
    "    \n",
    "    print(f\"Loading {max_slices} slices for 3D visualization...\")\n",
    "    indices = np.linspace(0, len(dcm_files)-1, max_slices, dtype=int)\n",
    "    \n",
    "    for idx in indices:\n",
    "        file_path = os.path.join(sequence_path, dcm_files[idx])\n",
    "        try:\n",
    "            dcm = pydicom.dcmread(file_path)\n",
    "            pixel_array = dcm.pixel_array\n",
    "            \n",
    "            # For multi-frame DICOM, use the middle frame\n",
    "            if len(pixel_array.shape) > 2 and pixel_array.shape[0] > 1:\n",
    "                middle_frame = pixel_array.shape[0] // 2\n",
    "                pixel_array = pixel_array[middle_frame]\n",
    "            \n",
    "            # Normalize to 0-1\n",
    "            if pixel_array.max() > 0:\n",
    "                pixel_array = pixel_array / pixel_array.max()\n",
    "            \n",
    "            slices.append(pixel_array)\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "    \n",
    "    if not slices:\n",
    "        print(\"No slices could be loaded for visualization.\")\n",
    "        return None\n",
    "    \n",
    "    # Create 3D visualization\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Get dimensions\n",
    "    z_size = len(slices)\n",
    "    y_size, x_size = slices[0].shape\n",
    "    \n",
    "    # Sample points for visualization (full resolution would be too dense)\n",
    "    sample_rate = 8  # Sample every 8th pixel\n",
    "    \n",
    "    # Create coordinate arrays\n",
    "    z, y, x = np.meshgrid(np.arange(z_size),\n",
    "                          np.arange(0, y_size, sample_rate),\n",
    "                          np.arange(0, x_size, sample_rate),\n",
    "                          indexing='ij')\n",
    "    \n",
    "    # Create value array\n",
    "    values = np.zeros((z_size, y_size // sample_rate, x_size // sample_rate))\n",
    "    for i in range(z_size):\n",
    "        values[i] = slices[i][::sample_rate, ::sample_rate]\n",
    "    \n",
    "    # Flatten arrays\n",
    "    x = x.flatten()\n",
    "    y = y.flatten()\n",
    "    z = z.flatten()\n",
    "    values = values.flatten()\n",
    "    \n",
    "    # Filter out low intensity points for clarity\n",
    "    threshold = 0.2\n",
    "    mask = values > threshold\n",
    "    \n",
    "    # Create scatter plot with color based on intensity\n",
    "    scatter = ax.scatter(x[mask], y[mask], z[mask], c=values[mask], cmap='viridis', alpha=0.3, s=5)\n",
    "    \n",
    "    # Add colorbar\n",
    "    fig.colorbar(scatter, ax=ax, label='Intensity')\n",
    "    \n",
    "    # Set labels\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z (Slice)')\n",
    "    ax.set_title(f'3D Visualization - {patient_id}, {sequence_name}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3D visualization for a sample patient and sequence\n",
    "# Replace with actual patient ID and sequence name from your dataset\n",
    "if dataset_info['patient_ids']:\n",
    "    sample_patient_id = dataset_info['patient_ids'][0]\n",
    "    \n",
    "    patient_details = dataset_info['patient_details'][sample_patient_id]\n",
    "    if patient_details['sequences']:\n",
    "        sample_sequence = patient_details['sequences'][0]\n",
    "        \n",
    "        # Create 3D visualization\n",
    "        create_3d_mri_visualization(sample_patient_id, sample_sequence, root_dir, dataset_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Full Dataset Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_complete_dataset(root_dir, output_dir=\"processed_data\", max_patients=None):\n",
    "    \"\"\"\n",
    "    Process the complete dataset and organize extracted information.\n",
    "    \"\"\"\n",
    "    print(f\"\\nProcessing complete dataset at {root_dir}\")\n",
    "    \n",
    "    # Create output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Step 1: Detect dataset structure\n",
    "    dataset_info = detect_dataset_structure(root_dir)\n",
    "    display_dataset_summary(dataset_info)\n",
    "    \n",
    "    # Limit number of patients to process if specified\n",
    "    if max_patients is not None and max_patients > 0:\n",
    "        patient_ids = dataset_info['patient_ids'][:max_patients]\n",
    "    else:\n",
    "        patient_ids = dataset_info['patient_ids']\n",
    "    \n",
    "    print(f\"\\nProcessing {len(patient_ids)} patients\")\n",
    "    \n",
    "    # Step 2: Extract demographics\n",
    "    demographics_df = extract_demographics(dataset_info, root_dir, sample_size=len(patient_ids))\n",
    "    if demographics_df is not None:\n",
    "        demographics_df.to_csv(os.path.join(output_dir, \"patient_demographics.csv\"), index=False)\n",
    "    \n",
    "    # Step 3: Process each patient's data\n",
    "    patients_data = []\n",
    "    \n",
    "    for patient_id in tqdm(patient_ids, desc=\"Processing patients\"):\n",
    "        patient_data = {\n",
    "            'patient_id': patient_id,\n",
    "            'sequences': []\n",
    "        }\n",
    "        \n",
    "        patient_details = dataset_info['patient_details'][patient_id]\n",
    "        patient_dir = os.path.join(root_dir, patient_id, patient_details['patient_directory'])\n",
    "        \n",
    "        for sequence in patient_details['sequences']:\n",
    "            sequence_path = os.path.join(patient_dir, sequence)\n",
    "            sequence_info = {\n",
    "                'name': sequence,\n",
    "                'file_count': patient_details['sequence_counts'].get(sequence, 0)\n",
    "            }\n",
    "            \n",
    "            # Try to read a sample DICOM file for metadata\n",
    "            dcm_files = [f for f in os.listdir(sequence_path) if f.endswith('.dcm')]\n",
    "            if dcm_files:\n",
    "                try:\n",
    "                    dicom_path = os.path.join(sequence_path, dcm_files[0])\n",
    "                    dcm = pydicom.dcmread(dicom_path)\n",
    "                    \n",
    "                    # Extract key metadata\n",
    "                    sequence_info['modality'] = getattr(dcm, 'Modality', 'Unknown')\n",
    "                    sequence_info['series_description'] = getattr(dcm, 'SeriesDescription', 'Unknown')\n",
    "                    sequence_info['image_size'] = f\"{dcm.Rows}x{dcm.Columns}\"\n",
    "                    \n",
    "                    # Check for multi-frame\n",
    "                    if hasattr(dcm, 'NumberOfFrames'):\n",
    "                        sequence_info['frames'] = int(dcm.NumberOfFrames)\n",
    "                    else:\n",
    "                        sequence_info['frames'] = 1\n",
    "                except Exception as e:\n",
    "                    sequence_info['error'] = str(e)\n",
    "            \n",
    "            patient_data['sequences'].append(sequence_info)\n",
    "            \n",
    "        patients_data.append(patient_data)\n",
    "    \n",
    "    # Step 4: Create summary report\n",
    "    report_file = os.path.join(output_dir, \"dataset_report.txt\")\n",
    "    with open(report_file, 'w') as f:\n",
    "        f.write(f\"Duke Breast Cancer MRI Dataset Report\\n\")\n",
    "        f.write(f\"Generated on: {pd.Timestamp.now()}\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Dataset location: {root_dir}\\n\")\n",
    "        f.write(f\"Total patients: {dataset_info['total_patients']}\\n\")\n",
    "        f.write(f\"Total studies: {dataset_info['total_studies']}\\n\")\n",
    "        f.write(f\"Total sequences: {dataset_info['total_sequences']}\\n\")\n",
    "        f.write(f\"Total DICOM files: {dataset_info['total_dcm_files']}\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Processed {len(patients_data)} patients\\n\\n\")\n",
    "        \n",
    "        # Add sequence type statistics\n",
    "        sequence_types = []\n",
    "        for patient in patients_data:\n",
    "            for seq in patient['sequences']:\n",
    "                if 'series_description' in seq:\n",
    "                    sequence_types.append(seq['series_description'])\n",
    "        \n",
    "        sequence_counter = Counter(sequence_types)\n",
    "        f.write(\"Sequence types in dataset:\\n\")\n",
    "        for seq_type, count in sequence_counter.most_common():\n",
    "            f.write(f\"  - {seq_type}: {count} occurrences\\n\")\n",
    "    \n",
    "    print(f\"\\nProcessing complete. Results saved to {output_dir}\")\n",
    "    print(f\"Summary report: {report_file}\")\n",
    "    \n",
    "    # Export detailed patient data as JSON\n",
    "    import json\n",
    "    with open(os.path.join(output_dir, \"patients_data.json\"), 'w') as f:\n",
    "        json.dump(patients_data, f, indent=2)\n",
    "    \n",
    "    return patients_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the complete dataset (or a limited number of patients)\n",
    "# Set max_patients to limit the number of patients to process (None for all)\n",
    "# processed_data = process_complete_dataset(root_dir, max_patients=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Conclusion and Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has provided a comprehensive exploration of the Duke Breast Cancer MRI dataset structure and contents. From here, you might want to:\n",
    "\n",
    "1. **Further analyze MRI dynamics**: Implement signal intensity curves analysis for DCE-MRI\n",
    "2. **Build ML models**: Develop machine learning models for lesion classification or segmentation\n",
    "3. **Perform advanced image processing**: Implement registration, segmentation, or feature extraction\n",
    "4. **Standardize the dataset**: Convert all images to a consistent format (NIfTI, etc.)\n",
    "5. **Create visualizations**: Develop more advanced visualization tools for clinical review\n",
    "\n",
    "The processed data and extracted metadata provide a solid foundation for further research with this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. References and Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [PyDICOM Documentation](https://pydicom.github.io/pydicom/stable/)\n",
    "- [Medical Image Processing with Python](https://www.sciencedirect.com/science/article/pii/S2352914821000137)\n",
    "- [Breast MRI Analysis Guide](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4950431/)\n",
    "- [DICOM Standard](https://www.dicomstandard.org/)\n",
    "- [NiBabel Documentation](https://nipy.org/nibabel/) - For more advanced MRI data processing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
