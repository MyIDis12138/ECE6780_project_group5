{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duke Breast Cancer MRI Dataset Explorer\n",
    "\n",
    "This notebook helps explore and analyze the Duke Breast Cancer MRI dataset with the following structure:\n",
    "```\n",
    "root_dir/\n",
    "├── Breast_MRI_001/\n",
    "│   └── patient_directory/\n",
    "│       ├── dynamic_sequence_1/\n",
    "│       │   └── *.dcm files\n",
    "│       ├── dynamic_sequence_2/\n",
    "│       │   └── *.dcm files\n",
    "│       └── ...\n",
    "├── Breast_MRI_002/\n",
    "└── ...\n",
    "```\n",
    "\n",
    "We'll use Python libraries for DICOM file processing and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydicom\n",
      "  Using cached pydicom-3.0.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy in /home/yang/miniconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: tqdm in /home/yang/miniconda3/lib/python3.12/site-packages (4.66.5)\n",
      "Requirement already satisfied: pillow in /home/yang/miniconda3/lib/python3.12/site-packages (11.1.0)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.56.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (101 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/yang/miniconda3/lib/python3.12/site-packages (from matplotlib) (24.1)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting python-dateutil>=2.7 (from matplotlib)\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/yang/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Using cached pydicom-3.0.1-py3-none-any.whl (2.4 MB)\n",
      "Downloading matplotlib-3.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading contourpy-1.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (323 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.56.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Using cached tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: pytz, tzdata, python-dateutil, pyparsing, pydicom, kiwisolver, fonttools, cycler, contourpy, pandas, matplotlib, seaborn\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.56.0 kiwisolver-1.4.8 matplotlib-3.10.1 pandas-2.2.3 pydicom-3.0.1 pyparsing-3.2.1 python-dateutil-2.9.0.post0 pytz-2025.1 seaborn-0.13.2 tzdata-2025.1\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "!pip install pydicom matplotlib numpy pandas seaborn tqdm pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "from collections import defaultdict, Counter\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset Detection Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_dataset_structure(root_dir):\n",
    "    \"\"\"\n",
    "    Explore the dataset structure and return summary statistics.\n",
    "    \"\"\"\n",
    "    print(f\"Analyzing dataset structure in: {root_dir}\")\n",
    "    \n",
    "    # Dictionary to store structure information\n",
    "    dataset_info = {\n",
    "        'total_patients': 0,\n",
    "        'total_studies': 0,\n",
    "        'total_sequences': 0,\n",
    "        'total_dcm_files': 0,\n",
    "        'patient_ids': [],\n",
    "        'patient_details': {}\n",
    "    }\n",
    "    \n",
    "    # Check if root directory exists\n",
    "    if not os.path.exists(root_dir):\n",
    "        print(f\"Error: The directory {root_dir} does not exist.\")\n",
    "        return dataset_info\n",
    "    \n",
    "    # Loop through first level directories (Breast_MRI_XXX)\n",
    "    for patient_folder in sorted(os.listdir(root_dir)):\n",
    "        patient_path = os.path.join(root_dir, patient_folder)\n",
    "        \n",
    "        if not os.path.isdir(patient_path) or not patient_folder.startswith('Breast_MRI_'):\n",
    "            continue\n",
    "            \n",
    "        dataset_info['total_patients'] += 1\n",
    "        dataset_info['patient_ids'].append(patient_folder)\n",
    "        \n",
    "        patient_info = {\n",
    "            'patient_directory': None,\n",
    "            'sequences': [],\n",
    "            'sequence_counts': {},\n",
    "            'total_files': 0\n",
    "        }\n",
    "        \n",
    "        # Find patient_directory within Breast_MRI_XXX\n",
    "        patient_subdirs = [d for d in os.listdir(patient_path) if os.path.isdir(os.path.join(patient_path, d))]\n",
    "        \n",
    "        if len(patient_subdirs) > 0:\n",
    "            patient_directory = patient_subdirs[0]  # Assuming there's only one directory per patient\n",
    "            patient_info['patient_directory'] = patient_directory\n",
    "            dataset_info['total_studies'] += 1\n",
    "            \n",
    "            patient_dir_path = os.path.join(patient_path, patient_directory)\n",
    "            \n",
    "            # Loop through sequences\n",
    "            for sequence_folder in sorted(os.listdir(patient_dir_path)):\n",
    "                sequence_path = os.path.join(patient_dir_path, sequence_folder)\n",
    "                \n",
    "                if os.path.isdir(sequence_path):\n",
    "                    dataset_info['total_sequences'] += 1\n",
    "                    patient_info['sequences'].append(sequence_folder)\n",
    "                    \n",
    "                    # Count DICOM files\n",
    "                    dcm_files = [f for f in os.listdir(sequence_path) if f.endswith('.dcm')]\n",
    "                    file_count = len(dcm_files)\n",
    "                    patient_info['sequence_counts'][sequence_folder] = file_count\n",
    "                    patient_info['total_files'] += file_count\n",
    "                    dataset_info['total_dcm_files'] += file_count\n",
    "        \n",
    "        dataset_info['patient_details'][patient_folder] = patient_info\n",
    "    \n",
    "    return dataset_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_dataset_summary(dataset_info):\n",
    "    \"\"\"\n",
    "    Display summary statistics of the dataset.\n",
    "    \"\"\"\n",
    "    print(\"\\n===== DATASET SUMMARY =====\")\n",
    "    print(f\"Total patients (Breast_MRI_XXX folders): {dataset_info['total_patients']}\")\n",
    "    print(f\"Total studies (patient directories): {dataset_info['total_studies']}\")\n",
    "    print(f\"Total sequences: {dataset_info['total_sequences']}\")\n",
    "    print(f\"Total DICOM files: {dataset_info['total_dcm_files']}\")\n",
    "    \n",
    "    if dataset_info['total_patients'] > 0:\n",
    "        avg_sequences = dataset_info['total_sequences'] / dataset_info['total_patients']\n",
    "        avg_files = dataset_info['total_dcm_files'] / dataset_info['total_patients']\n",
    "        print(f\"Average sequences per patient: {avg_sequences:.2f}\")\n",
    "        print(f\"Average DICOM files per patient: {avg_files:.2f}\")\n",
    "        \n",
    "        # Collect sequence names across patients\n",
    "        all_sequences = []\n",
    "        for patient_id, details in dataset_info['patient_details'].items():\n",
    "            all_sequences.extend(details['sequences'])\n",
    "            \n",
    "        sequence_counts = Counter(all_sequences)\n",
    "        print(\"\\nMost common sequence names:\")\n",
    "        for seq, count in sequence_counts.most_common(10):\n",
    "            print(f\"  - {seq}: {count} occurrences\")\n",
    "            \n",
    "        # Sample of patients\n",
    "        print(\"\\nSample of patient IDs:\")\n",
    "        for patient_id in sorted(dataset_info['patient_ids'])[:5]:\n",
    "            print(f\"  - {patient_id}\")\n",
    "        if len(dataset_info['patient_ids']) > 5:\n",
    "            print(f\"  - ... and {len(dataset_info['patient_ids']) - 5} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Detect the Duke Breast Cancer MRI Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing dataset structure in: ../data/Duke-Breast-Cancer-MRI\n",
      "\n",
      "===== DATASET SUMMARY =====\n",
      "Total patients (Breast_MRI_XXX folders): 1\n",
      "Total studies (patient directories): 1\n",
      "Total sequences: 6\n",
      "Total DICOM files: 842\n",
      "Average sequences per patient: 6.00\n",
      "Average DICOM files per patient: 842.00\n",
      "\n",
      "Most common sequence names:\n",
      "  - 3.000000-ax t1-75455: 1 occurrences\n",
      "  - 600.000000-ax 3d dyn MP-31458: 1 occurrences\n",
      "  - 601.000000-Ph1ax 3d dyn MP-61179: 1 occurrences\n",
      "  - 602.000000-Ph2ax 3d dyn MP-76388: 1 occurrences\n",
      "  - 603.000000-Ph3ax 3d dyn MP-16301: 1 occurrences\n",
      "  - 604.000000-Ph4ax 3d dyn MP-57837: 1 occurrences\n",
      "\n",
      "Sample of patient IDs:\n",
      "  - Breast_MRI_358\n"
     ]
    }
   ],
   "source": [
    "# Set the root directory path\n",
    "root_dir = \"../data/Duke-Breast-Cancer-MRI\"  # Change this to your actual path\n",
    "\n",
    "# Detect dataset structure\n",
    "dataset_info = detect_dataset_structure(root_dir)\n",
    "\n",
    "# Display summary\n",
    "display_dataset_summary(dataset_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyze DICOM Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_dicom_metadata(dataset_info, root_dir, sample_size=5):\n",
    "    \"\"\"\n",
    "    Sample DICOM files from different patients and extract metadata.\n",
    "    \"\"\"\n",
    "    metadata_samples = []\n",
    "    sample_count = 0\n",
    "    \n",
    "    # Try to get samples from different patients\n",
    "    for patient_id in dataset_info['patient_ids']:\n",
    "        if sample_count >= sample_size:\n",
    "            break\n",
    "            \n",
    "        patient_details = dataset_info['patient_details'][patient_id]\n",
    "        patient_dir = os.path.join(root_dir, patient_id, patient_details['patient_directory'])\n",
    "        \n",
    "        # Try each sequence\n",
    "        for sequence in patient_details['sequences']:\n",
    "            if sample_count >= sample_size:\n",
    "                break\n",
    "                \n",
    "            sequence_path = os.path.join(patient_dir, sequence)\n",
    "            dcm_files = [f for f in os.listdir(sequence_path) if f.endswith('.dcm')]\n",
    "            \n",
    "            if dcm_files:\n",
    "                # Get the first DICOM file\n",
    "                dicom_path = os.path.join(sequence_path, dcm_files[0])\n",
    "                try:\n",
    "                    dcm = pydicom.dcmread(dicom_path)\n",
    "                    metadata_samples.append({\n",
    "                        'patient_id': patient_id,\n",
    "                        'sequence': sequence,\n",
    "                        'file': dcm_files[0],\n",
    "                        'dicom': dcm\n",
    "                    })\n",
    "                    sample_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading DICOM file {dicom_path}: {e}\")\n",
    "    \n",
    "    return metadata_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_dicom_metadata(metadata_samples):\n",
    "    \"\"\"\n",
    "    Display metadata from sampled DICOM files.\n",
    "    \"\"\"\n",
    "    common_tags = ['PatientName', 'PatientID', 'PatientBirthDate', 'PatientSex',\n",
    "                   'StudyDescription', 'SeriesDescription', 'Modality',\n",
    "                   'Manufacturer', 'ManufacturerModelName', 'MagneticFieldStrength',\n",
    "                   'PixelSpacing', 'SliceThickness', 'RepetitionTime', 'EchoTime']\n",
    "    \n",
    "    for i, sample in enumerate(metadata_samples, 1):\n",
    "        dcm = sample['dicom']\n",
    "        print(f\"\\n===== DICOM Sample {i} =====\")\n",
    "        print(f\"Patient ID: {sample['patient_id']}\")\n",
    "        print(f\"Sequence: {sample['sequence']}\")\n",
    "        print(f\"File: {sample['file']}\")\n",
    "        print(\"\\nKey Metadata:\")\n",
    "        \n",
    "        for tag in common_tags:\n",
    "            if hasattr(dcm, tag):\n",
    "                print(f\"  - {tag}: {getattr(dcm, tag)}\")\n",
    "        \n",
    "        print(f\"\\nImage dimensions: {dcm.Rows} x {dcm.Columns}\")\n",
    "        if hasattr(dcm, 'NumberOfFrames'):\n",
    "            print(f\"Number of frames: {dcm.NumberOfFrames}\")\n",
    "        \n",
    "        # Add more MRI-specific tags\n",
    "        mri_tags = ['ScanningSequence', 'SequenceVariant', 'ScanOptions', 'ContrastBolusAgent']\n",
    "        print(\"\\nMRI-specific tags:\")\n",
    "        for tag in mri_tags:\n",
    "            if hasattr(dcm, tag):\n",
    "                print(f\"  - {tag}: {getattr(dcm, tag)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
